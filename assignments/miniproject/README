Mini project
====================

For this assignment, we revisit the task of compiling Cish to RISC-V
that we originally completed in Problem Set 4, but this time our goal
is to produce much higher performing RISC-V output.

Specifically, your task is to implement the function "compile" in
cish_compile.ml, which takes a Cish program as input and should return
a list of RISC-V assembly instructions as output. But whereas before
you were assessed solely based on whether the RISC-V you generated
returned the correct outputs, this time you will also be evaluated on
the performance (in terms of running time) that the generated RISC-V
takes.

Running make in the current directory generates an executable called
proj, which expects a file to compile and a file name to use to store
the source output.  That is, running:

./proj test/01cexpr_01add.cish tmp.s

Creates a file tmp.s with the assembly generated by the compiler.
You can then assemble it using docker-gcc.sh, and run it using
docker-temu.sh/docker-qemu.sh as in PS3 or PS4. Refer back to the
instructions there if you forgot.


Details about performance evaluation:
====================

We will be assessing the performance of your compiler's generated code
for 6 benchmark programs included in the "bench/" subdirectory.

To assess the performance of a program, instead of using qemu or temu,
we will use an emulator that actually also tries to simulate how long
operations take, such as completing an instruction, accessing a piece
of memory, etc.  We'll use the gem5 simulator, which is widely used in
computer architecture research. Gem5 allows you to simulate a wide
range of potential computer organizations with different performance
characteristics.  For simplicity, we'll be using a simulated machine
with the following characteristics:

(1) Simple in-order CPU with a 2 Ghz clock cycle
(2) A memory cache for instructions (icache), no cache for data
(3) 512 MB of DDR3 ram

The exact details of this machine are not too important, but more or
less the important thing to keep in mind is that because it does not
have a cache for data, accessing the stack is always very, very slow
compared to accessing a register, because every stack access must go
to memory. Moreover, because it executes in order, when a memory
access occurs, the CPU must stall to wait for that memory access to
finish before it can complete any remaining instructions.  (Modern
out-of-order processors can mask some of the memory access delay time
by continuing to execute other instructions that don't depend on the
results of the instruction that is accessing memory.)

I have packaged gem5 with this configuration in a docker image, which
you can download from the BrightSpace page. Assuming you have followed
the instructions there for setting up the docker image, then you can
run the following the following:

./proj test/10fun_01call.cish tmp.s
sh ./docker-gcc.sh tmp.s -o a.out
sh ./docker-gem5.sh a.out

which will run the gem5 simulation on the result of compiling
01cexpr_01add.cish.  You should see a number print out after a moment
which is the number of "simulator clock ticks" that the program ran
for. For example, when using my solution from PS4, the number printed
is 6747000. Note that the simulation frequency is 1000000000000 ticks
per second, so this corresponds to 0.000006747 simulated "seconds".

The simulator will also produce a file called stats.txt that contains
lots of additional statistics about the execution. (Most of this
information is more than what we need for the project, but it is
interesting!)

Grading
=====================

Your submission will be scored based on how much better it does
compared to the performance of a "baseline" compiler, which
corresponds to my PS4 solution. In the directory bench/soln-timing,
for each benchmark, there is a file containing the number of ticks
that this baseline compiler's generated code took on that benchmark.
For each benchmark, the autograder takes your generated code's tick
number and divides it by the baseline's tick number to get a
"normalized" running time.  Then, it computes the geometric average of
these normalized running times for each benchmark.  Let x be this
geometric average. Then, the following function assigns points on a
scale from 0 to 100 based on the value of x:

```
let ratio_to_raw (x : float) : int =
  if x <= 0.65 then
    100
  else if x <= 0.8 then
    90
  else if x <= 0.9 then
    80
  else if x < 1.0 then
    70
  else
    0
```

In other words, if the geometric average is below 0.65 then you get a
100, below 0.8 then 90, etc. Call this the "top 6" point score.

To make things slightly more generous, we additionally also compute
the geometric average of your top 4 and top 5 best programs, and also
compute what ratio_to_raw would be for the top 4 and top 5 programs.
For the top 4 score, we deduct 20 points, and for the top 5 best we
deduct 10 points.  Your overall score is then we take the maximum of
the top 4, top 5, and top 6 points.

In other words, this means if you have 1 test case that just performs
very, very poorly that drags your geometric average up, but your other
5 test cases have a geometric average below 0.65 then you can still
get a score of 90.

Of course, performance is not everything -- the generated programs
should still compute the correct value! In particular, if your
generated program for a benchmark is incorrect, it is given a maximum
score (so essentially it will be dropped when computing the top 4 or
top 5).

** IMPORTANT: ** Note that these are "minimum guaranteed" scores for the
project component of the grade. I reserve the right to curve these
scores up, but I will not curve this score down (except for cases of
academic dishonesty, exploiting a bug in the grader, etc.)

Getting started
=====================

In the starter code, there is already code for converting a Cish
program to a Cfg representation, and for converting a Cfg program
(without temps) into a RISC-V program. Feel free to re-use these --
though you will need to figure out how to get rid of the temps, either
by allocating them to a register or spilling. Take a look at
cish_compile.ml for a sketch of the structure of a compiler that
re-uses these components.


Submission
=====================

To submit your work, upload:

cish_compile.ml --- (mandatory)
cfg.ml          --- (optional, only if you edited it)
description.txt --- (optional, a brief description of what you implemented in your compiler)


Hints
=====================

I was able to get a score of 100 with a very rudimentary graph
coloring register allocator that "just" does the simplest description
of graph coloring that we discussed in class, without trying to do
coalescing or any of the more advanced features.

You can try to improve performance by doing CSE or other optimizations
we discussed in class, though note that given the absence of a data
cache and the other system parameters, the "big" wins here will come
from avoiding unnecessary memory accesses.